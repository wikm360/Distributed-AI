# ğŸŒ Distributed AI Chat System (DAI)

[![Flutter](https://img.shields.io/badge/Flutter-3.x-02569B?logo=flutter)](https://flutter.dev)
[![Python](https://img.shields.io/badge/Python-3.9+-3776AB?logo=python)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active%20Development-yellow)](https://github.com)

> **Democratizing AI through distributed, privacy-first collective intelligence**

A revolutionary chat platform that runs Large Language Models (LLMs) directly on user devices, leveraging distributed computing and collective knowledge instead of centralized servers. Built with Flutter and powered by community collaboration.

---

## ğŸ¯ Vision

In a world dominated by centralized AI services, **DAI** brings a paradigm shift: 

- **ğŸ”“ No Vendor Lock-in**: Break free from expensive API subscriptions
- **ğŸ”’ Privacy First**: All processing happens locally on your device
- **ğŸ¤ Collective Intelligence**: Everyone contributes and benefits
- **âš¡ Distributed Power**: Harness combined computational resources
- **ğŸŒ Equal Access**: Advanced AI for everyone, regardless of resources

---

## âœ¨ Key Features

### ğŸ§  On-Device AI Engines
- **Gemma Engine**: Google's Gemma models running locally
- **Qwen Engine**: Alibaba's Qwen 2.5 models support
- **Llama Engine**: GGUF format models via LlamaCpp

### ğŸ”— Distributed Architecture
- **Routing Server**: FastAPI-based coordination layer
- **Worker Nodes**: Devices sharing computational power
- **P2P Network** *(Coming Soon)*: Serverless peer-to-peer communication

### ğŸ“š RAG (Retrieval Augmented Generation)
- **Local Knowledge Base**: ObjectBox-powered vector storage
- **Smart Retrieval**: Context-aware document search
- **Embedding Service**: Semantic understanding of queries

### ğŸ¨ Modern UI/UX
- Material Design 3
- Real-time streaming responses
- Model management dashboard
- Worker status visualization

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Device                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Chat UI     â”‚  â”‚  AI Engine   â”‚  â”‚  RAG System  â”‚      â”‚
â”‚  â”‚  (Flutter)   â”‚â”€â–¶â”‚  (Local LLM) â”‚â—€â”€â”‚  (ObjectBox) â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                                      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                      â”‚
          â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Routing Server (FastAPI)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚Load Balancer â”‚  â”‚ Task Queue   â”‚  â”‚ Worker Pool  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                      â”‚
          â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker Node 1     â”‚            â”‚   Worker Node N     â”‚
â”‚  (Shared Device)    â”‚    ...     â”‚  (Shared Device)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

### Prerequisites

#### For Mobile App:
- Flutter SDK 3.x+
- Android SDK (API 24+) or iOS 12+
- Minimum 4GB RAM
- 3GB storage space

#### For Routing Server:
- Python 3.9+
- FastAPI
- 1GB RAM VPS

### Installation

#### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/wikm360/Distributed-AI.git
cd distributed-ai-chat
```

#### 2ï¸âƒ£ Setup Flutter App
```bash
cd mobile
flutter pub get
flutter run
```

#### 3ï¸âƒ£ Setup Routing Server
```bash
cd Routing-server
pip install -r requirements.txt
python Routing.py
```

#### 4ï¸âƒ£ Download AI Models
Open the app, navigate to Model Store, and download your preferred model:
- Gemma 2B (Lightweight)
- Qwen 2.5 0.5B (Lightweight)
- Qwen 2.5 7B (Balanced)
- Llama 3 8B (Advanced)

---

## ğŸ’¡ How It Works

### Local Mode
1. User sends a query
2. Local AI engine processes the request
3. RAG system retrieves relevant context
4. Response streams back in real-time

### Distributed Mode
1. Query sent to Routing Server
2. Server distributes task to available Workers
3. Workers process using local models + RAG
4. Results aggregated and returned to user

---

## ğŸ—ºï¸ Roadmap

### âœ… Phase 1: Local Models & RAG (Completed)
- [x] Local LLM execution
- [x] ObjectBox vector database
- [x] RAG implementation
- [x] Multi-engine support

### âœ… Phase 2: Distributed Network (Completed)
- [x] Routing server
- [x] Worker nodes
- [x] Load balancing

### ğŸ”„ Phase 3: RAG & Model Optimization (In Progress)
- [x] RAG chunking strategy optimization
- [x] Embedding model fine-tuning
- [x] Vector DB indexing optimization
- [ ] Model quantization & compression
- [ ] Inference speed benchmarking
- [ ] Memory footprint reduction

### ğŸ”„ Phase 4: Persian Language Support (In Progress)
- [ ] Persian UI localization
- [ ] Persian model training & fine-tuning
- [ ] Farsi OCR support
- [ ] Persian RAG knowledge bases
- [ ] Right-to-left (RTL) UI adaptation
- [ ] Persian NLP preprocessing

### ğŸ”„ Phase 5: P2P Decentralization (In Progress)
- [ ] Serverless peer-to-peer routing
- [ ] DHT-based node discovery
- [ ] Blockchain-based trust system

### ğŸ”® Phase 6: Federated Learning
- [ ] On-device model fine-tuning
- [ ] Gradient sharing (privacy-preserving)
- [ ] FedAvg/FedProx implementation

### ğŸ® Phase 7: Gamification & Social
- [ ] Trust score system
- [ ] User levels & missions
- [ ] Topic-based collaboration spaces
- [ ] Reputation rewards

### ğŸ› ï¸ Phase 8: Developer Ecosystem
- [ ] Open SDK release
- [ ] Plugin system
- [ ] API documentation
- [ ] Community marketplace

---

## ğŸŒŸ Why DAI?

| Feature | Traditional AI | DAI |
|---------|---------------|-----|
| **Privacy** | Data sent to servers | 100% local processing |
| **Cost** | Subscription fees | Free & open source |
| **Access** | Internet required | Works offline |
| **Ownership** | Vendor lock-in | You own your data |
| **Learning** | Centralized training | Federated learning |
| **Community** | Passive consumers | Active contributors |

---

## ğŸ¤ Contributing

We believe in collective intelligence! Here's how you can help:

### For Developers
- ğŸ› Report bugs and issues
- ğŸ’» Submit pull requests
- ğŸ“ Improve documentation
- ğŸ§ª Write tests

### For AI Enthusiasts
- ğŸ§  Fine-tune models for specific languages
- ğŸ“š Contribute to knowledge bases
- ğŸ” Improve RAG performance
- ğŸ“Š Share benchmarks

### For Community
- ğŸŒ Translate the app
- ğŸ“¢ Spread the word
- ğŸ’¡ Suggest features
- ğŸ¨ Design UI/UX improvements

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ›¡ï¸ Privacy & Security

- **ğŸ” End-to-End Encryption**: All network communication is encrypted
- **ğŸ  Local Processing**: Your data never leaves your device
- **ğŸ•µï¸ No Tracking**: We don't collect personal information
- **ğŸ” Differential Privacy**: Federated learning protects user data
- **ğŸ›¡ï¸ Malicious Node Detection**: Built-in security against bad actors

---

## ğŸ“Š Technical Stack

### Frontend
- **Framework**: Flutter 3.x
- **State Management**: Provider / Riverpod
- **Database**: ObjectBox (vector DB)
- **AI Runtime**: LiteRT, Edge-AI

### Backend
- **Server**: Python FastAPI

### AI/ML
- **Inference**: LlamaCpp, ONNX Runtime
- **Embeddings**: SentenceTransformers
- **Fine-tuning**: LoRA, QLoRA

---

## ğŸ“ˆ Performance

| Model | Size | Speed (tokens/s) | RAM Usage |
|-------|------|------------------|-----------|
| Gemma 2B | 1.4GB | 15-20 | 2.5GB |
| Qwen 2.5 7B | 4.1GB | 8-12 | 5GB |
| Llama 3 8B | 4.7GB | 6-10 | 6GB |

*Benchmarks on Snapdragon 8 Gen 2, Android 13*

---

## ğŸŒ Use Cases

- **ğŸ“ Education**: Student collaboration with AI tutors
- **ğŸ¢ Enterprise**: Private AI for sensitive data
- **ğŸŒ Remote Areas**: Offline AI assistance
- **ğŸ”¬ Research**: Distributed model training
- **ğŸ’¬ Communities**: Topic-based knowledge sharing

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Flutter Team**: For the amazing cross-platform framework
- **LlamaCpp**: For efficient local inference
- **ObjectBox**: For fast vector database
- **Hugging Face**: For open-source models
- **Community Contributors**: For making this possible

---

## ğŸ“ Contact & Support

- **My Site**: [My Site](https://wikm.ir)


<div align="center">

### ğŸš€ Join the AI Revolution!

**Together, we're building the future of decentralized intelligence**

[â­ Star this repo](https://github.com/wikm360/Distributed-AI) â€¢ [ğŸ´ Fork it](https://github.com/wikm360/Distributed-AI/fork)

</div>

---

<div align="center">
Made with â¤ï¸ by wikm
</div>
